{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM w praktyce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#he found one simple trick to ignore warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "# fmnist - domyślnie jest 60k treningowych i 10k testowych\n",
    "(x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# polaczenie w 1 zbior\n",
    "x_fmnist=np.concatenate((x_train_fmnist,x_test_fmnist))\n",
    "y_fmnist=np.concatenate((y_train_fmnist,y_test_fmnist))\n",
    "\n",
    "\n",
    "# tng\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "newsgroups_train = fetch_20newsgroups_vectorized(subset='all')\n",
    "\n",
    "news_x = newsgroups_train.data\n",
    "news_y = newsgroups_train.target\n",
    "\n",
    "x, y = resample(news_x, news_y, n_samples=18000, replace=False, random_state=0)\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.4, random_state=0 )\n",
    "\n",
    "\n",
    "# MISC FUNKCJE DO POTENCJALNEGO WYKORZYSTANIA\n",
    "\n",
    "# x_train = x_train.reshape((x_train.shape[0],-1))\n",
    "# x_test = x_test.reshape((x_test.shape[0],-1))\n",
    "# x_train, y_train = resample(x_train, y_train, n_samples=60000, replace=False, random_state=0)\n",
    "# x_test, y_test = resample(x_test, y_test, n_samples=10000, replace=False, random_state=0)\n",
    "\n",
    "# #SVM\n",
    "# tng_df=SVM_analyze(x_train,y_train,x_test,y_test)\n",
    "# tng_df\n",
    "\n",
    "# y_train = y_train.reshape((y_train.shape[0],))\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler_mnist = StandardScaler().fit(x_train)\n",
    "# x_train = scaler_mnist.transform(x_train)\n",
    "# x_test = scaler_mnist.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pełen zbiór SVC\n",
    "# clf = SVC(C=100, kernel='linear')\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('kernel=linear, C=%f, score=%f' %(100, score))\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "def select_random_features(X, feats_num):\n",
    "    random_feats = random.choices(list(range(X.shape[1])), k=feats_num)\n",
    "    col_selector = ColumnSelector(cols=random_feats)\n",
    "    return col_selector.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [100, 300, 500, 1000, 2000, 3000, 4000]\n",
    "num_feats = [100, 1300, 6500, 13000, 26000, 39000, 52000]\n",
    "\n",
    "for i in num_samples:\n",
    "    for j in num_feats:\n",
    "        x, y = resample(news_x, news_y, n_samples=i, replace=False, random_state=0)\n",
    "        X_r = select_random_features(x, j)\n",
    "        x_train, x_test, y_train, y_test =  train_test_split(X_r, y, test_size=0.4, random_state=0)\n",
    "        clf = SVC(C=100, kernel='linear')\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print('samples=%d, feats=%d, score=%f' %(i, j, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_SVM(x, y, split, max_iter):\n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=split, random_state=0)\n",
    "    clf = SVC(C=100, kernel='linear', max_iter=max_iter)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('\\t- accuracy = %f' %(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sub_SVM(x, y, split, max_iter):\n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=split, random_state=0)\n",
    "\n",
    "    clfs_pipe = []\n",
    "    clfs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        clf = SVC(C=100, kernel='linear', probability=True, max_iter=max_iter)\n",
    "        name = 'svc' + str(i)\n",
    "        # 10% cech\n",
    "        feats_num = int(0.15 * x.shape[1])\n",
    "        random_feats = random.choices(list(range(x.shape[1])), k=feats_num)\n",
    "        \n",
    "        col_sel = ColumnSelector(cols=random_feats)\n",
    "        clf_pipe = Pipeline([('sel', col_sel), (name, clf)])\n",
    "        p_name = 'pipe' + str(i)\n",
    "        clfs_pipe.append((p_name, clf_pipe))\n",
    "        clfs.append(clf)\n",
    "    \n",
    "    eclf = VotingClassifier(estimators=clfs_pipe, voting='soft')\n",
    "    eclf = eclf.fit(x_train, y_train)\n",
    "    y_pred = eclf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('\\t- voting score = %f' %(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_train_size(x, y, max_iter=-1):\n",
    "    # pelny SVM\n",
    "    # docelowo caly zbior, ale dla sprawdzenia poprawnosci i zobaczenia wynikow w realnym czasie wycinamy z niego 10% \n",
    "    samples_num = int(0.1*x.shape[0])\n",
    "    x1, y1 = resample(x, y, n_samples=samples_num, replace=False, random_state=0)\n",
    "    \n",
    "    #zbior pod-SVMow\n",
    "    x2, y2 = resample(x, y, n_samples=500, replace=False, random_state=0)\n",
    "    split_sizes=range(1,10)\n",
    "    \n",
    "    for split_size in split_sizes:\n",
    "        split=split_size/10\n",
    "        print('\\nTest size =', split)\n",
    "        analyze_SVM(x1, y1, split, max_iter)\n",
    "        analyze_sub_SVM(x2, y2, split, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_train_size(news_x, news_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = x_fmnist.shape\n",
    "x_fmnist_reshaped = x_fmnist.reshape((d1, d2*d3))\n",
    "compare_train_size(x_fmnist_reshaped, y_fmnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations=[10,100,1000]\n",
    "\n",
    "def compute_limit_iterations(x,y):\n",
    "    for max_iter in max_iterations:\n",
    "        print('\\n ## ITERATIONS =', max_iter,' ##\\n')    \n",
    "        compare_train_size(x, y, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_limit_iterations(news_x, news_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = x_fmnist.shape\n",
    "x_fmnist_reshaped = x_fmnist.reshape((d1, d2*d3))\n",
    "compute_limit_iterations(x_fmnist_reshaped, y_fmnist)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ŚMIETNIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_random_features(X, feats_num):\n",
    "    arrX = X.toarray()\n",
    "    X_random = []\n",
    "    random_feats = random.choices(list(range(arrX.shape[1])), k=feats_num)\n",
    "    X_random = arrX[:, random_feats]\n",
    "    result = select_features(X, random_feats)\n",
    "    return result, random_feats\n",
    "\n",
    "\n",
    "def select_features(X, feats):\n",
    "    arrX = X.toarray()\n",
    "    X_random = []\n",
    "    X_random = arrX[:, feats]\n",
    "    return np.asarray(X_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wszystkich cech jest 130k\n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False, random_state=0)\n",
    "\n",
    "## RANDOM\n",
    "X_r, x_feats = select_random_features(x, 13000)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_r, y, test_size=0.4, random_state=0)\n",
    "clf = SVC(C=100, kernel='linear')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Random accuracy', score)\n",
    "\n",
    "## KBEST\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "clf = SVC(C=100, kernel='linear')\n",
    "X_kbest = SelectKBest(chi2, k=1300).fit_transform(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_kbest, y, test_size=0.4, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Kbest accuracy', score)\n",
    "    \n",
    "## RFE    \n",
    "# from sklearn.feature_selection import RFE\n",
    "# clf = SVC(C=100, kernel='linear')\n",
    "# rfe_selector = RFE(estimator=clf, n_features_to_select=10, step=100)\n",
    "# X_rfe = rfe_selector.fit_transform(x, y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.4, random_state=0)\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('RFE accuracy', score)\n",
    "\n",
    "\n",
    "## SFS\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# clf = SVC(C=100, kernel='linear')\n",
    "# sfsForward = SFS(clf, k_features=10, forward=True, n_jobs=-1)\n",
    "# X_sfs = sfsForward.fit_transform(x, y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_sfs, y, test_size=0.4, random_state=0)\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('SFS accuracy', score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zespół podklasyfikatorw SVM\n",
    "## wszystkie podklasyfikatory uczą sie na tym samym zbiorze danych\n",
    "## jedynie każdy podklasyfikator losuje swój zbiór cech i wycina z danych, tylko interesujące go cechy\n",
    "## wyniki póki co są dosyć satysfakcjonujące \n",
    "## ... ale aby sprawdzić to dla większego zbiory danych potrzeba troche czasu lub lepszej maszyny\n",
    "\n",
    "clfs = []\n",
    "fts = []\n",
    "\n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "print(\"TRAINING\")\n",
    "for i in range(10):\n",
    "    print('#', end='')\n",
    "    x_train_r, feats = select_random_features(x_train, 13000)\n",
    "    clf = SVC(C=100, kernel='linear')\n",
    "    clf = clf.fit(x_train_r, y_train)\n",
    "    clfs.append(clf)\n",
    "    fts.append(feats)\n",
    "    \n",
    "    \n",
    "    \n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "print(\"\\n\\nTEST\")\n",
    "for i in range(10):\n",
    "    clf = clfs[i]\n",
    "    feats = fts[i]\n",
    "    x_test_r = select_features(x_test, feats)\n",
    "    y_pred = clf.predict(x_test_r)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('SVM-' + str(i), 'accuracy =', score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_analyze(x_train,y_train,x_test,y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    arrC=[0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "    kernelArr=[]\n",
    "    supportArrC=[]\n",
    "    arrDegree=[]\n",
    "    arrScore=[]\n",
    "    arrCoef0=[]\n",
    "    \n",
    "    for C in arrC:\n",
    "        clf = SVC(C=C, kernel='linear')\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        kernelArr.append(\"linear\")\n",
    "        supportArrC.append(C)\n",
    "        arrDegree.append(\"\")\n",
    "        arrScore.append(score)\n",
    "        arrCoef0.append(\"\")        \n",
    "\n",
    "    for C in arrC:\n",
    "        for degree in [2,3,4]:\n",
    "            clf = SVC(C=C, kernel='poly', degree=degree)\n",
    "            clf.fit(x_train,y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            kernelArr.append(\"poly\")\n",
    "            supportArrC.append(C)\n",
    "            arrDegree.append(degree)\n",
    "            arrScore.append(score)\n",
    "            arrCoef0.append(\"\")\n",
    "\n",
    "    for C in arrC:\n",
    "        for coef0 in [0.0,0.5,1.0]:\n",
    "            clf = SVC(C=C, kernel='sigmoid', coef0=coef0)\n",
    "            clf.fit(x_train,y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            kernelArr.append(\"sigmoid\")\n",
    "            supportArrC.append(C)\n",
    "            arrDegree.append(\"\")\n",
    "            arrScore.append(score)\n",
    "            arrCoef0.append(coef0)\n",
    "\n",
    "    dataframe=pd.DataFrame({\"C\":supportArrC,\"degree\":arrDegree,\"coef0\":arrCoef0,\"score\":arrScore,\"kernel\":kernelArr})\n",
    "    \n",
    "    return dataframe.style.apply(lambda x: [\"background: red\" if v == x.max() else \"\" for v in x], axis = 0, subset=\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm.SVC pozwala na dobieranie kernela oraz parametrów uczenia.\n",
    "\n",
    "Możliwe kernele to: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ albo kernel stworzony przez siebie.\n",
    "\n",
    "Najważniejsze parametry uczenia, których wartości można dobierać, to:\n",
    "- C: parametr służący do regularyzacji, proporcjonalny do 1/lambda. Musi być liczbą dodatnią (default=1.0)\n",
    "- degree: stopień wielomianu (przy użyciu kernela 'poly')\n",
    "- gamma: współczynnik dla kerneli 'rbf', 'poly', 'sigmoid' ze zbioru {'scale', 'auto'} albo float (default='scale')\n",
    "- coef0: wartość \"r\" dla kerneli 'poly' i 'sigmoid', float (default=0.0)\n",
    "\n",
    "(szczegóły: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html )"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
