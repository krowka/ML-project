{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM w praktyce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#he found one simple trick to ignore warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#set only 3 precision\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmnist - domyślnie jest 60k treningowych i 10k testowych\n",
    "(x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# polaczenie w 1 zbior\n",
    "x_fmnist=np.concatenate((x_train_fmnist,x_test_fmnist))\n",
    "y_fmnist=np.concatenate((y_train_fmnist,y_test_fmnist))\n",
    "\n",
    "\n",
    "# tng\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "newsgroups_train = fetch_20newsgroups_vectorized(subset='all')\n",
    "\n",
    "news_x = newsgroups_train.data\n",
    "news_y = newsgroups_train.target\n",
    "\n",
    "x, y = resample(news_x, news_y, n_samples=18000, replace=False, random_state=0)\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.4, random_state=0 )\n",
    "\n",
    "\n",
    "# MISC FUNKCJE DO POTENCJALNEGO WYKORZYSTANIA\n",
    "\n",
    "# x_train = x_train.reshape((x_train.shape[0],-1))\n",
    "# x_test = x_test.reshape((x_test.shape[0],-1))\n",
    "# x_train, y_train = resample(x_train, y_train, n_samples=60000, replace=False, random_state=0)\n",
    "# x_test, y_test = resample(x_test, y_test, n_samples=10000, replace=False, random_state=0)\n",
    "\n",
    "# #SVM\n",
    "# tng_df=SVM_analyze(x_train,y_train,x_test,y_test)\n",
    "# tng_df\n",
    "\n",
    "# y_train = y_train.reshape((y_train.shape[0],))\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler_mnist = StandardScaler().fit(x_train)\n",
    "# x_train = scaler_mnist.transform(x_train)\n",
    "# x_test = scaler_mnist.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "def select_random_features(X, feats_num):\n",
    "    random_feats = random.choices(list(range(X.shape[1])), k=feats_num)\n",
    "    col_selector = ColumnSelector(cols=random_feats)\n",
    "    return col_selector.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [100, 300, 500, 1000, 3000, 5000]\n",
    "num_feats = [100, 1300, 6500, 13000, 26000, 39000, 52000]\n",
    "\n",
    "samples=[]\n",
    "features=[]\n",
    "scores=[]\n",
    "\n",
    "for i in num_samples:\n",
    "    x, y = resample(news_x, news_y, n_samples=i, replace=False, random_state=0)\n",
    "    for j in num_feats:\n",
    "        X_r = select_random_features(x, j)\n",
    "        x_train, x_test, y_train, y_test =  train_test_split(X_r, y, test_size=0.4, random_state=0)\n",
    "        clf = SVC(C=100, kernel='linear')\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        samples.append(i)\n",
    "        features.append(j)\n",
    "        scores.append(score)\n",
    "        print('samples=%d, feats=%d, score=%f' %(i, j, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame({\"samples\":samples,\"features\":features,\"accuracy\":scores})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot=dataframe.pivot(index='samples', columns='features', values='accuracy')\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.style.apply(lambda x: [\"background: red\" if v == x.max() else \"\" for v in x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.apionly as sns\n",
    "ax = sns.heatmap(pivot, square=True)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90 )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_SVM(x, y, split, max_iter):\n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=split, random_state=0)\n",
    "    clf = SVC(C=100, kernel='linear', max_iter=max_iter)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('\\t- accuracy = %f' %(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sub_SVM(x, y, split, max_iter):\n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=split, random_state=0)\n",
    "\n",
    "    clfs_pipe = []\n",
    "    clfs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        clf = SVC(C=100, kernel='linear', probability=True, max_iter=max_iter)\n",
    "        name = 'svc' + str(i)\n",
    "        # 10% cech\n",
    "        feats_num = int(0.15 * x.shape[1])\n",
    "        random_feats = random.choices(list(range(x.shape[1])), k=feats_num)\n",
    "        \n",
    "        col_sel = ColumnSelector(cols=random_feats)\n",
    "        clf_pipe = Pipeline([('sel', col_sel), (name, clf)])\n",
    "        p_name = 'pipe' + str(i)\n",
    "        clfs_pipe.append((p_name, clf_pipe))\n",
    "        clfs.append(clf)\n",
    "    \n",
    "    eclf = VotingClassifier(estimators=clfs_pipe, voting='soft')\n",
    "    eclf = eclf.fit(x_train, y_train)\n",
    "    y_pred = eclf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('\\t- voting score = %f' %(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_train_size(x, y, max_iter=-1):\n",
    "    matrix=[]\n",
    "    \n",
    "    # pelny SVM\n",
    "    # docelowo caly zbior, ale dla sprawdzenia poprawnosci i zobaczenia wynikow w realnym czasie wycinamy z niego 10% \n",
    "    samples_num = int(0.1*x.shape[0])\n",
    "    x1, y1 = resample(x, y, n_samples=samples_num, replace=False, random_state=0)\n",
    "    \n",
    "    #zbior pod-SVMow\n",
    "    x2, y2 = resample(x, y, n_samples=500, replace=False, random_state=0)\n",
    "    split_sizes=range(1,10)\n",
    "    \n",
    "    for split_size in split_sizes:\n",
    "        row=[]\n",
    "        split=split_size/10\n",
    "        print('\\nTrain size =', 1-split)\n",
    "        row.append(1-split)\n",
    "        row.append(analyze_SVM(x1, y1, split, max_iter))\n",
    "        row.append(analyze_sub_SVM(x2, y2, split, max_iter))\n",
    "        matrix.append(row)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=compare_train_size(news_x, news_y)\n",
    "dataframe=pd.DataFrame(matrix,columns=['Test_Size','full_accuracy','voting_accuracy'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = x_fmnist.shape\n",
    "x_fmnist_reshaped = x_fmnist.reshape((d1, d2*d3))\n",
    "matrix=compare_train_size(x_fmnist_reshaped, y_fmnist)\n",
    "dataframe=pd.DataFrame(matrix,columns=['Test_Size','full_accuracy','voting_accuracy'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations=[10,100,1000,10000]\n",
    "\n",
    "def compute_limit_iterations(x,y):\n",
    "    dataframes=[]\n",
    "    \n",
    "    for max_iter in max_iterations:\n",
    "        print('\\n ## ITERATIONS =', max_iter,' ##\\n')    \n",
    "        matrix=compare_train_size(x, y, max_iter)\n",
    "        df=pd.DataFrame(matrix,columns=['Test_Size','full_accuracy','voting_accuracy'])\n",
    "        df['iters']=max_iter\n",
    "        dataframes.append(df)\n",
    "\n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_tng_df=compute_limit_iterations(news_x, news_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_tng_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tng_pivots=[]\n",
    "tng_pivots.append(big_tng_df.pivot(index='Test_Size', columns='iters', values='full_accuracy'))\n",
    "tng_pivots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tng_pivots.append(big_tng_df.pivot(index='Test_Size', columns='iters', values='voting_accuracy'))\n",
    "tng_pivots[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.apionly as sns\n",
    "ax1 = sns.heatmap(tng_pivot, square=True)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90 )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.apionly as sns\n",
    "ax2 = sns.heatmap(tng_pivot2, square=True)\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=90 )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharey='row')\n",
    "\n",
    "axes[0].set_yticks(range(len(pivot.index)))\n",
    "axes[0].set_yticklabels(pivot.index)\n",
    "axes[0].set_ylabel(\"Train Size\")\n",
    "\n",
    "for pivot,ax in zip(tng_pivots,axes):\n",
    "    im=ax.imshow(pivot, cmap=\"Greens\")\n",
    "\n",
    "    ax.set_xticks(range(len(pivot.columns)))\n",
    "    ax.set_xticklabels(pivot.columns, rotation=90)\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "    \n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "# axes[0].setp(ax2.xaxis.get_majorticklabels(), rotation=90 )\n",
    "# axes[1].plot(ax2.xaxis.get_majorticklabels(), rotation=90 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = x_fmnist.shape\n",
    "x_fmnist_reshaped = x_fmnist.reshape((d1, d2*d3))\n",
    "compute_limit_iterations(x_fmnist_reshaped, y_fmnist)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "def random_label(label, a, b):\n",
    "    new_label = random.randint(a, b)\n",
    "    while new_label == label:\n",
    "        new_label = random.randint(a, b)\n",
    "    return new_label\n",
    "    \n",
    "    \n",
    "\n",
    "def noise_label(y, noise_size, labels_count):\n",
    "    if noise_size == 0:\n",
    "        return y\n",
    "    \n",
    "    y_noised = np.array(y)\n",
    "    \n",
    "    noise_num = int(noise_size*y_noised.shape[0])\n",
    "    random_noise = random.choices(list(range(y_noised.shape[0])), k=noise_num)\n",
    "    for i in random_noise:\n",
    "        y_noised[i] = random_label(y_noised[i], 0, labels_count)\n",
    "    return y_noised\n",
    "\n",
    "\n",
    "\n",
    "def noise_fmnist(x, noise_size):\n",
    "    if noise_size == 0:\n",
    "        return x\n",
    "    \n",
    "    x_noised = np.array(x)\n",
    "    noise_level = 0.2 ## mozna sprawdzic rozne poziomy zaszumienia\n",
    "    \n",
    "    noise_num = int(noise_size*x_noised.shape[0])\n",
    "    random_noise = random.choices(list(range(x_noised.shape[0])), k=noise_num)\n",
    "    for i in random_noise:\n",
    "        image = x_noised[i].reshape((28, 28))\n",
    "       \n",
    "        aug = iaa.AdditiveGaussianNoise(scale=(0, noise_level*255))\n",
    "        blurred = aug(images=[image])\n",
    "        noised_image = blurred[0]\n",
    "        x_noised[i] = noised_image.reshape((28*28))\n",
    "    return x_noised\n",
    "\n",
    "\n",
    "\n",
    "def noise_tng(x, noise_size):\n",
    "    if noise_size == 0:\n",
    "        return x.toarray()\n",
    "    \n",
    "    ## konwersja do array, zeby moc zmieniac komorki tablicy (sparse matrix do tego sie nie nada)\n",
    "    x_noised = np.array(x.toarray())\n",
    "    noise_num = int(noise_size*x_noised.shape[0])\n",
    "    random_noise = random.choices(list(range(x_noised.shape[0])), k=noise_num)\n",
    "    for i in random_noise:\n",
    "        x_noised[i] = noise_vector(x_noised[i])\n",
    "    return x_noised\n",
    "\n",
    "\n",
    "\n",
    "def noise_vector(vector):\n",
    "    noise_level = 0.2 ## mozna sprawdzic rozne poziomy zaszumienia\n",
    "    \n",
    "    vector_noised = []\n",
    "    \n",
    "    for i in range(vector.shape[0]):\n",
    "        val = vector[i]\n",
    "        \n",
    "        if val == 0:\n",
    "            bound = 0.1\n",
    "        else:\n",
    "            bound = noise_level * val\n",
    "        \n",
    "        noise = random.uniform(-bound, bound)\n",
    "        vector_noised.append(val + noise)\n",
    "    \n",
    "    vector_noised = np.array(vector_noised)\n",
    "    return vector_noised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = resample(news_x, news_y, n_samples=1000, replace=False, random_state=0)\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clfs_pipe = []\n",
    "clfs = []\n",
    "\n",
    "for i in range(10):\n",
    "    clf = SVC(C=100, kernel='linear', probability=True)\n",
    "    name = 'svc' + str(i)\n",
    "    feats_num = int(0.2 * x.shape[1])\n",
    "    random_feats = random.choices(list(range(x.shape[1])), k=feats_num)\n",
    "    col_sel = ColumnSelector(cols=random_feats)\n",
    "    clf_pipe = Pipeline([('sel', col_sel), (name, clf)])\n",
    "    p_name = 'pipe' + str(i)\n",
    "    clfs_pipe.append((p_name, clf_pipe))\n",
    "    clfs.append(clf)\n",
    "    \n",
    "# deklaracja klasyfiaktorow\n",
    "eclf = VotingClassifier(estimators=clfs_pipe, voting='hard')\n",
    "svc = SVC(C=100, kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### LABEL NOISE ###\n",
      "\n",
      "noise_level =  0.0\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.486667\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.473333\n",
      "\n",
      "noise_level =  0.1\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.420000\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.450000\n",
      "\n",
      "noise_level =  0.2\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.390000\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.413333\n",
      "\n",
      "noise_level =  0.3\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.343333\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.353333\n",
      "\n",
      "noise_level =  0.4\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.356667\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.336667\n",
      "\n",
      "noise_level =  0.5\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.316667\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.310000\n",
      "\n",
      "noise_level =  0.6\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.266667\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.286667\n",
      "\n",
      "noise_level =  0.7\n",
      "\t- SVC\n",
      "\t    noise accuracy = 0.280000\n",
      "\t- Voting\n",
      "\t    noise accuracy = 0.216667\n"
     ]
    }
   ],
   "source": [
    "## bledne etykiety\n",
    "print(\"### LABEL NOISE ###\")\n",
    "\n",
    "for s in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print('\\nnoise_level = ', s)\n",
    "    \n",
    "    for (name, clf) in [('SVC', svc), ('Voting', eclf)]:\n",
    "        print(\"\\t-\", name)\n",
    "        \n",
    "        y_noised = noise_label(y_train, s, 19) ## tng 20 cech\n",
    "        clf.fit(x_train, y_noised)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print('\\t    noise accuracy = %f' %(score))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bledne wektory, baaaardzo dlugo sie licza\n",
    "print(\"### VECTOR NOISE ###\")\n",
    "\n",
    "for s in [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    print('\\nnoise_level = ', s)\n",
    "    \n",
    "    for (name, clf) in [('SVC', svc), ('Voting', eclf)]:\n",
    "        print(\"\\t-\", name)\n",
    "        \n",
    "        x_noised = noise_tng(x_train, s)\n",
    "        clf.fit(x_noised, y_train)\n",
    "        y_pred = clf.predict(x_test.toarray()) ## konwersja sparse matrix do array\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print('\\t    vector noise accuracy = %f' %(score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3 = x_fmnist.shape\n",
    "x_fmnist_reshaped = x_fmnist.reshape((d1, d2*d3))\n",
    "\n",
    "x, y = resample(x_fmnist_reshaped, y_fmnist, n_samples=1000, replace=False, random_state=0)\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clfs_pipe = []\n",
    "clfs = []\n",
    "\n",
    "for i in range(10):\n",
    "    clf = SVC(C=100, kernel='linear', probability=True)\n",
    "    name = 'svc' + str(i)\n",
    "    feats_num = int(0.2 * x.shape[1])\n",
    "    random_feats = random.choices(list(range(x.shape[1])), k=feats_num)\n",
    "    col_sel = ColumnSelector(cols=random_feats)\n",
    "    clf_pipe = Pipeline([('sel', col_sel), (name, clf)])\n",
    "    p_name = 'pipe' + str(i)\n",
    "    clfs_pipe.append((p_name, clf_pipe))\n",
    "    clfs.append(clf)\n",
    "    \n",
    "# deklaracja klasyfiaktorow\n",
    "eclf = VotingClassifier(estimators=clfs_pipe, voting='soft')\n",
    "svc = SVC(C=100, kernel='linear')\n",
    "\n",
    "\n",
    "# for s in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "#     print('\\nnoise_level = ', s)\n",
    "    \n",
    "#     for (name, clf) in [('SVC', svc), ('Voting', eclf)]:\n",
    "#         print(\"\\t-\", name)\n",
    "        \n",
    "#         y_noised = noise_label(y_train, s, 9) # fmnist 10 cech\n",
    "#         clf.fit(x_train, y_noised)\n",
    "#         y_pred = clf.predict(x_test)\n",
    "#         score = accuracy_score(y_test, y_pred)\n",
    "#         print('\\t\\t+ label noise accuracy = %f' %(score))\n",
    "        \n",
    "#         x_noised = noise_fmnist(x_train, s) \n",
    "#         clf.fit(x_noised, y_train)\n",
    "#         y_pred = clf.predict(x_test)\n",
    "#         score = accuracy_score(y_test, y_pred)\n",
    "#         print('\\t\\t+ vector noise accuracy = %f' %(score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### LABEL NOISE ###\n",
      "\n",
      "noise_level =  0.0\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.806667\n",
      "\t- Voting\n",
      "\t    label noise accuracy = 0.780000\n",
      "\n",
      "noise_level =  0.1\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.783333\n",
      "\t- Voting\n",
      "\t    label noise accuracy = 0.763333\n",
      "\n",
      "noise_level =  0.2\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.623333\n",
      "\t- Voting\n",
      "\t    label noise accuracy = 0.710000\n",
      "\n",
      "noise_level =  0.3\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.600000\n",
      "\t- Voting\n",
      "\t    label noise accuracy = 0.666667\n",
      "\n",
      "noise_level =  0.4\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.573333\n",
      "\t- Voting\n",
      "\t    label noise accuracy = 0.610000\n",
      "\n",
      "noise_level =  0.5\n",
      "\t- SVC\n",
      "\t    label noise accuracy = 0.503333\n",
      "\t- Voting\n"
     ]
    }
   ],
   "source": [
    "## bledne etykiety \n",
    "print(\"### LABEL NOISE ###\")\n",
    "\n",
    "for s in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    print('\\nnoise_level = ', s)\n",
    "    \n",
    "    for (name, clf) in [('SVC', svc), ('Voting', eclf)]:\n",
    "        print(\"\\t-\", name)\n",
    "        \n",
    "        y_noised = noise_label(y_train, s, 9) # fmnist 10 cech\n",
    "        clf.fit(x_train, y_noised)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print('\\t    label noise accuracy = %f' %(score))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bledne wektory\n",
    "print(\"### VECTOR NOISE ###\")\n",
    "\n",
    "\n",
    "for s in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    print('\\nnoise_level = ', s)\n",
    "    for (name, clf) in [('SVC', svc), ('Voting', eclf)]:\n",
    "        print(\"\\t-\", name)\n",
    "        \n",
    "        x_noised = noise_fmnist(x_train, s) \n",
    "        clf.fit(x_noised, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print('\\t    vector noise accuracy = %f' %(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ŚMIETNIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_random_features(X, feats_num):\n",
    "    arrX = X.toarray()\n",
    "    X_random = []\n",
    "    random_feats = random.choices(list(range(arrX.shape[1])), k=feats_num)\n",
    "    X_random = arrX[:, random_feats]\n",
    "    result = select_features(X, random_feats)\n",
    "    return result, random_feats\n",
    "\n",
    "\n",
    "def select_features(X, feats):\n",
    "    arrX = X.toarray()\n",
    "    X_random = []\n",
    "    X_random = arrX[:, feats]\n",
    "    return np.asarray(X_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wszystkich cech jest 130k\n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False, random_state=0)\n",
    "\n",
    "## RANDOM\n",
    "X_r, x_feats = select_random_features(x, 13000)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_r, y, test_size=0.4, random_state=0)\n",
    "clf = SVC(C=100, kernel='linear')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Random accuracy', score)\n",
    "\n",
    "## KBEST\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "clf = SVC(C=100, kernel='linear')\n",
    "X_kbest = SelectKBest(chi2, k=1300).fit_transform(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_kbest, y, test_size=0.4, random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Kbest accuracy', score)\n",
    "    \n",
    "## RFE    \n",
    "# from sklearn.feature_selection import RFE\n",
    "# clf = SVC(C=100, kernel='linear')\n",
    "# rfe_selector = RFE(estimator=clf, n_features_to_select=10, step=100)\n",
    "# X_rfe = rfe_selector.fit_transform(x, y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.4, random_state=0)\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('RFE accuracy', score)\n",
    "\n",
    "\n",
    "## SFS\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# clf = SVC(C=100, kernel='linear')\n",
    "# sfsForward = SFS(clf, k_features=10, forward=True, n_jobs=-1)\n",
    "# X_sfs = sfsForward.fit_transform(x, y)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_sfs, y, test_size=0.4, random_state=0)\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print('SFS accuracy', score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zespół podklasyfikatorw SVM\n",
    "## wszystkie podklasyfikatory uczą sie na tym samym zbiorze danych\n",
    "## jedynie każdy podklasyfikator losuje swój zbiór cech i wycina z danych, tylko interesujące go cechy\n",
    "## wyniki póki co są dosyć satysfakcjonujące \n",
    "## ... ale aby sprawdzić to dla większego zbiory danych potrzeba troche czasu lub lepszej maszyny\n",
    "\n",
    "clfs = []\n",
    "fts = []\n",
    "\n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "print(\"TRAINING\")\n",
    "for i in range(10):\n",
    "    print('#', end='')\n",
    "    x_train_r, feats = select_random_features(x_train, 13000)\n",
    "    clf = SVC(C=100, kernel='linear')\n",
    "    clf = clf.fit(x_train_r, y_train)\n",
    "    clfs.append(clf)\n",
    "    fts.append(feats)\n",
    "    \n",
    "    \n",
    "    \n",
    "x, y = resample(news_x, news_y, n_samples=500, replace=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "print(\"\\n\\nTEST\")\n",
    "for i in range(10):\n",
    "    clf = clfs[i]\n",
    "    feats = fts[i]\n",
    "    x_test_r = select_features(x_test, feats)\n",
    "    y_pred = clf.predict(x_test_r)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('SVM-' + str(i), 'accuracy =', score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_analyze(x_train,y_train,x_test,y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    arrC=[0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "    kernelArr=[]\n",
    "    supportArrC=[]\n",
    "    arrDegree=[]\n",
    "    arrScore=[]\n",
    "    arrCoef0=[]\n",
    "    \n",
    "    for C in arrC:\n",
    "        clf = SVC(C=C, kernel='linear')\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        kernelArr.append(\"linear\")\n",
    "        supportArrC.append(C)\n",
    "        arrDegree.append(\"\")\n",
    "        arrScore.append(score)\n",
    "        arrCoef0.append(\"\")        \n",
    "\n",
    "    for C in arrC:\n",
    "        for degree in [2,3,4]:\n",
    "            clf = SVC(C=C, kernel='poly', degree=degree)\n",
    "            clf.fit(x_train,y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            kernelArr.append(\"poly\")\n",
    "            supportArrC.append(C)\n",
    "            arrDegree.append(degree)\n",
    "            arrScore.append(score)\n",
    "            arrCoef0.append(\"\")\n",
    "\n",
    "    for C in arrC:\n",
    "        for coef0 in [0.0,0.5,1.0]:\n",
    "            clf = SVC(C=C, kernel='sigmoid', coef0=coef0)\n",
    "            clf.fit(x_train,y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            kernelArr.append(\"sigmoid\")\n",
    "            supportArrC.append(C)\n",
    "            arrDegree.append(\"\")\n",
    "            arrScore.append(score)\n",
    "            arrCoef0.append(coef0)\n",
    "\n",
    "    dataframe=pd.DataFrame({\"C\":supportArrC,\"degree\":arrDegree,\"coef0\":arrCoef0,\"score\":arrScore,\"kernel\":kernelArr})\n",
    "    \n",
    "    return dataframe.style.apply(lambda x: [\"background: red\" if v == x.max() else \"\" for v in x], axis = 0, subset=\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm.SVC pozwala na dobieranie kernela oraz parametrów uczenia.\n",
    "\n",
    "Możliwe kernele to: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ albo kernel stworzony przez siebie.\n",
    "\n",
    "Najważniejsze parametry uczenia, których wartości można dobierać, to:\n",
    "- C: parametr służący do regularyzacji, proporcjonalny do 1/lambda. Musi być liczbą dodatnią (default=1.0)\n",
    "- degree: stopień wielomianu (przy użyciu kernela 'poly')\n",
    "- gamma: współczynnik dla kerneli 'rbf', 'poly', 'sigmoid' ze zbioru {'scale', 'auto'} albo float (default='scale')\n",
    "- coef0: wartość \"r\" dla kerneli 'poly' i 'sigmoid', float (default=0.0)\n",
    "\n",
    "(szczegóły: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html )"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
